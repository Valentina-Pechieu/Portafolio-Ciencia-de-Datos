# 📂 Portafolio Ciencia de Datos

Este repositorio contiene los proyectos desarrollados como parte de la **Evaluación Final de los Módulos de Ciencia de Datos**.  
Cada código aborda técnicas de análisis, visualización y modelado de datos en Python o PySpark.

## 📌 Contenido

- **Sistema de compras en librería**  
  Implementación de un sistema en Python que gestiona inventario, aplica descuentos y genera facturas con cálculo de ahorros totales.

- **Análisis de datos de migración**  
  Limpieza y transformación de datos con Pandas y NumPy.  
  Identificación de outliers, reemplazo de valores, análisis exploratorio, agrupamientos y exportación de datos procesados.

- **Análisis de atletas olímpicos**  
  Exploración de datos, estadística descriptiva, correlaciones y regresión lineal.  
  Incluye visualizaciones con Seaborn y Matplotlib.

- **Análisis experimental del programa de tutoría**  
  Aplicación de pruebas de hipótesis con **t-test** e intervalos de confianza.  
  Visualización de resultados con boxplots e histogramas.

- **Clustering en géneros musicales**  
  Comparación de algoritmos de clustering (**K-Means, Jerárquico, DBSCAN**) y reducción de dimensionalidad con **PCA** y **t-SNE**.

- **Predicción de natalidad con redes neuronales**  
  Modelado predictivo usando **Keras/TensorFlow**.  
  Comparación de configuraciones de activación y learning rate.  
  Evaluación con métricas (MAE, MSE, RMSE, R²).

- **Análisis de migraciones con PySpark**  
  Procesamiento de datos con **RDDs, DataFrames y SQL** en Spark.  
  Entrenamiento de un modelo de **Regresión Logística** con pipeline (StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler).  
  Evaluación con métricas de clasificación (Accuracy, Precision, Recall, F1).

## ⚙️ Tecnologías utilizadas

- **Python 3**  
- **Pandas, NumPy, Seaborn, Matplotlib, Statsmodels, Scikit-learn**  
- **TensorFlow / Keras**  
- **PySpark (RDDs, DataFrames, MLlib)**  

## 📊 Objetivo

Este portafolio demuestra la aplicación práctica de técnicas de **análisis de datos, estadística, machine learning y big data**, integrando herramientas del ecosistema Python y Spark para resolver problemas de distintas áreas: comercio, migración, deportes, educación, música y demografía.

## 📚 Referencias y Fuentes

- Todos los datasets utilizados fueron provistos en las **evaluaciones finales del curso de Ciencia de Datos**.  
- Los datasets son de carácter **educativo** y fueron diseñados para practicar técnicas de análisis, estadística, machine learning y big data.
- Documentación oficial utilizada como referencia:
  - [Pandas](https://pandas.pydata.org/)  
  - [NumPy](https://numpy.org/)  
  - [Scikit-learn](https://scikit-learn.org/stable/)  
  - [TensorFlow/Keras](https://www.tensorflow.org/)  
  - [Apache Spark](https://spark.apache.org/docs/latest/)  
